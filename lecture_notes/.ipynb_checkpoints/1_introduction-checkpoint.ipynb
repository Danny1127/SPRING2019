{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages for this lecture\n",
    "# To install, use the following code\n",
    "# using Pkg\n",
    "# Pkg.add(\"Plots\") ...\n",
    "using Plots\n",
    "using CompEcon\n",
    "using ForwardDiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dynamic Optimization\n",
    "\n",
    "# (aka computational methods for economists)\n",
    "\n",
    "# AEM 7130\n",
    "\n",
    "# Ivan Rudik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What this class is about\n",
    "1. Learning how to compute dynamic models through approximation and estimation\n",
    "2. Other useful computational techniques\n",
    "3. Learning important details about computing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What you need to succeed in this course\n",
    "1. ECON 6090 and ECON 6170\n",
    "2. Or potentially some other classes (see me)\n",
    "3. Previous coding experience or willingness to spend some time learning as you go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Course materials\n",
    "1. Everything we use in the course will be <div class=\"blue\">**freely available**</div> and posted to the course GitHub (details next class on how to use Git)\n",
    "2. Books (free from the library or authors' websites):\n",
    "  1. Judd (1998)\n",
    "  2. Miranda and Fackler (2002)\n",
    "  3. Nocedal and Wright (2006)\n",
    "  4. Karp and Traeger (2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Things to do before next class\n",
    "- Set up a GitHub account at https://github.com\n",
    "- Set up a JuliaBox account at https://juliabox.com\n",
    "  - You can also use CISER resources if you'd like\n",
    "- Spend some time reading *Learn Julia the Hard Way* or the http://quantecon.org tutorials for Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What we will cover in the class\n",
    "1. Basic computing and things you need to think about (matrix inversion, integration, truncation, machine precision, etc)\n",
    "2. Coding and version control\n",
    "3. Optimization\n",
    "4. Numerical and empirical dynamic modeling\n",
    "5. Efficiently taking (difficult!) expectations\n",
    "6. High performance computing (parallelization, GPUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What you have to do\n",
    "- Come to class\n",
    "- 5 computational problem sets\n",
    "- Final research project proposal\n",
    "- Final research project\n",
    "- One presentation of a paper from the literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Important days / times\n",
    "- Office hours: Tuesday 1:30-3:00 in Warren 462\n",
    "- Final project proposal:\n",
    "- Final project paper:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Grading\n",
    "- Problem sets: 50% (10% each)\n",
    "- Final project proposal: 10%\n",
    "- Final project paper/presentation: 20%\n",
    "- Class participation: 10%\n",
    "- Computational paper presentation: 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problem sets (10% each)\n",
    "\n",
    "You must submit them as a Jupyter notebook\n",
    "\n",
    "This means they must be in Julia, Python, or R, but I recommend Julia since I'll be using it in class\n",
    "\n",
    "You can work in groups of up to 3\n",
    "\n",
    "Problem sets will be where you **implement** the techniques we learn in class on your own, but we will be doing our fair share of coding in class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Computational paper presentations (10%)\n",
    "\n",
    "Everyone will present a numerical paper starting about half way through the class\n",
    "\n",
    "The paper can apply methods we've learned about, or can be a new method that we have not covered\n",
    "\n",
    "Consult with me at least 1 week prior to your scheduled presentation date to get the paper okayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Final project (20% paper, 10% proposal)\n",
    "\n",
    "The final project will be the beginning of a **computationally-driven** research project\n",
    "\n",
    "Proposals will be due about half way through the class\n",
    "\n",
    "Everyone will present their final projects in the last week of class\n",
    "\n",
    "More details on the syllabus and to come later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class will take place inside Jupyter notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Why not beamer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(\"So we can run code inside the slides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# true coefficient\n",
    "bbeta = π\n",
    "# random x data\n",
    "x = randn(100,1)*5 .+ 3\n",
    "# OLS data generating process\n",
    "y = bbeta.*x .+ randn(100,1)*10\n",
    "\n",
    "# OLS estimation\n",
    "bbeta_hat = inv(x'x)x'y\n",
    "\n",
    "println(\"β-hat is $(round(bbeta_hat[1],digits=3)) and the true β is $(round(bbeta,digits=3)).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why do we need computational methods?\n",
    "Everything you've done so far has likely been solvable analytically\n",
    "\n",
    "Including OLS: $\\hat{\\beta} = (X'X)^{-1}X'Y$\n",
    "\n",
    "**<div class=\"blue\"> Not all economic models have closed-form solutions,  \n",
    "and others can't have closed-form solutions with losing important economic content</div>**\n",
    "\n",
    "This is generally true for dynamic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example 1\n",
    "\n",
    "Suppose we have a constant elasticity demand function: $q(p) = p^{-0.2}$\n",
    "\n",
    "In equilibrium, quantity demanded is $q^* = 2$\n",
    "\n",
    "**What price clears the market in equilibrium?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Just invert the demand function:\n",
    "\n",
    "$2 = p^{-0.2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$p^* = 2^{-0.2} \\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Your calculator can do the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example 2\n",
    "Suppose the demand function is now: $q(p) = 0.5p^{-0.2} + 0.5p^{-0.5}$, a weighted average of two CE demand functions\n",
    "\n",
    "**What price clears the market if $q^*=2$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, does a solution exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Yes. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$q(p)$ is monotonically increasing\n",
    "\n",
    "$q(p)$ is less than 2 at $p=0.1$ and greater than 2 at $p=0.2$\n",
    "\n",
    "$\\rightarrow$ by intermediate value theorem $q(p) = 2$ somewhere in $(0.1,0.2)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We know solution is between .1 and .2\n",
    "x = collect(range(.1,stop=.2,length=1000)) # generate evenly spaced grid between .1 and .2\n",
    "q_d = ones(size(x)).*2                     # generate equal length vector of quantity demanded=2\n",
    "\n",
    "# Price function\n",
    "price(p) = p.^(-0.2)/2 .+ p.^(-0.5)/2\n",
    "\n",
    "# Get corresponding quantity values at these prices\n",
    "y = price(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# plot the price as a function of Q\n",
    "plot(x, [y q_d],\n",
    "    linestyle = [:solid :dot],\n",
    "    linewidth = [3 3],\n",
    "    linecolor = [:red :blue],\n",
    "    grid = :false,\n",
    "    tickfontsize = 12,\n",
    "    xlabel = \"p\",\n",
    "    ylabel = \"q(p)\",\n",
    "    label = [\"q(p)\" \"Quantity Demanded\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Notice: if we let $t = p^{-0.1}$ then:\n",
    "\n",
    "$q(t) = 0.5t^2 + 0.5t^5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can we solve for $t$ now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "No! Closed-form solutions to fifth order   \n",
    "polynomials are not guaranteed to exist!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So how do we solve the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Newton's method\n",
    "Iteratively do the following:\n",
    "1. Guess solution to: $q(p) - q^* = 0 \\rightarrow q(p) - 2 = 0$\n",
    "2. Approximate the function with local  \n",
    "second order polynomial around guess\n",
    "3. Solve this easier equation\n",
    "4. Solution is the new guess\n",
    "5. Stop if previous guess and new guess are sufficiently close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "p = .3        # initial guess\n",
    "deltap = 1e10 # initialize stepsize\n",
    "demand(p) = p^(-0.2)/2 + p^(-0.5)/2 - 2     # quantity minus price\n",
    "demand_grad(p) = .1*p^(-1.2) + .25*p^(-1.5) # gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# iterate on Newton's method\n",
    "while abs(deltap) > 1e-4\n",
    "    deltap = demand(p)/demand_grad(p)\n",
    "    p += deltap\n",
    "    println(\"Intermediate guess of p = $(round(p,digits=3)).\")\n",
    "end\n",
    "println(\"The solution is p = $(round(p,digits=3)).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will learn how and why this method works in a few classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example 3\n",
    "\n",
    "Consider a two period ag commodity market model\n",
    "\n",
    "Period 1: Farmer makes acreage decisions for planting  \n",
    "Period 2: Per-acre yield realizes, equilibrium crop price clears the market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The farmer's policy function is: $a(E[p]) = \\frac{1}{2} + \\frac{1}{2}E[p]$\n",
    "\n",
    "After planting, yield $\\hat{y}$ realizes, producing a total quantity $q = a\\hat{y}$ of the crop\n",
    "\n",
    "Demand is given by $p(q) = 3-2q$\n",
    "\n",
    "Yield is given by $\\hat{y} \\sim \\mathcal{N}(1,0.1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**How much acreage does the farmer plant?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$p(\\hat{y}) = 3-2a\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$a = \\frac{1}{2} + \\frac{1}{2}(3-2aE[\\hat{y}])$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Rearrange and solve:\n",
    "\n",
    "$a^* = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now suppose the government implements a price floor on the crop of $p > 1$ so we have that $p(\\hat{y}) = \\max(1,3-2a\\hat{y})$\n",
    "\n",
    "**How much acreage does the farmer plant?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is analytically intractable\n",
    "\n",
    "The max operator is non-linear so we can't pass the expectation through\n",
    "\n",
    "$E[\\max(1,3-2a\\hat{y})] \\neq \\max(1,E[3-2a\\hat{y}])$\n",
    "\n",
    "$\\rightarrow$ we need to solve this numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a scheme that allows us to approximate a continuous distribution\n",
    "# with a discrete distribution (we will learn about this later)\n",
    "y, weights = qnwnorm(12, 1, 0.1)\n",
    "\n",
    "# solve the problem via function iteration (exploits fixed points)\n",
    "a = 1.         # initial guess\n",
    "p = 0.         # define price outside the loop (more later)\n",
    "exp_price = 0.\n",
    "diff = 100.    # initialize error\n",
    "\n",
    "while diff > 1e-4\n",
    "    a_old = a                      # save old acreage\n",
    "    p = max.(1,3 .- 2 .*a.*y)      # compute price at all distribution points\n",
    "    exp_price = (weights'*p)[1]    # compute expected price\n",
    "    a = 1/2 + 1/2*exp_price        # get new acreage planted given new price\n",
    "    diff = abs(a-a_old)            # change in acreage planted\n",
    "    println(\"Intermediate acreage guess: $(round(a,digits=3))\")\n",
    "end\n",
    "\n",
    "println(\"The optimal number of acres to plant is $(round(a,digits=3)).\")\n",
    "println(\"The expected price is $(round(exp_price,digits=3)).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Big O Notation\n",
    "\n",
    "How do we quantify **speed** and **accuracy** of computational algorithms?\n",
    "\n",
    "i.e. what is the **computational complexity** of the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**General mathematical definition:** Big O notation describes the limiting behavior of a function when the argument tends towards a particular value or infinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Programming context:** Describes the limiting behavior of algorithms in terms of run time/memory/accuracy as input size grows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You've seen this before in the expression of Taylor series' errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Big O Notation\n",
    "\n",
    "Written as: **O(F(x))**\n",
    "\n",
    "Here is how to think about it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**O(x):** linear\n",
    "- Time to solve increases linearly in input x\n",
    "- Accuracy changes linearly in input x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Examples?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Time to find a particular (e.g. maximum) value in an unsorted array\n",
    "\n",
    "$\\rightarrow$ For each element, check whether it is the value we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Big O Notation\n",
    "\n",
    "**O($\\mathbf{c^n}$):** exponential\n",
    "- Time to solve increases exponentially in input x\n",
    "- Accuracy changes exponentially in input x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Examples?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Time to solve a standard dynamic program, ex traveling salesman\n",
    "\n",
    "$\\rightarrow$ For each city, solve a Bellman as a function of all other cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Big O Notation\n",
    "\n",
    "**O($n!$):** factorial\n",
    "- Time to solve increases factorially in input x\n",
    "- Accuracy changes factorially in input x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Examples?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Solving traveling salesman by brute force\n",
    "\n",
    "$\\rightarrow$ Obtain travel time for all possible combinations of intermediate cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Big O Notation: Accuracy example\n",
    "\n",
    "This is how you have probably seen Big O used before:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Taylor series for $sin(x)$ around zero:\n",
    "\n",
    "$sin(x) \\approx x - x^3/3! + x^5/5! + O(x^7)$\n",
    "\n",
    "What does $O(x^7)$ mean here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As we move away from $0$ to some $x$, the upper bound of the growth rate in the error of our approximation to $sin(x)$ is $x^7$\n",
    "\n",
    "We are approximating about zero so $x$ is small and $x^n$ is decreasing in $n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For small $x$, higher order polynomials mean the error will grow slower and we have a better local approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Sin example, print relative errors\n",
    "\n",
    "# sin(x) = 0, approximation is a polynomial without a constant so also zero\n",
    "println(\"Error of fifth-order approximation at x=0 is: 0\")\n",
    "\n",
    "# fifth and third order Taylor approximations\n",
    "sin_error_5(x) = sin(x) - (x - x^3/6 + x^5/120)\n",
    "sin_error_3(x) = sin(x) - (x - x^3/6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = .001\n",
    "println(\"Error of fifth-order approximation at x = $x is: $(sin_error_5(x))\")\n",
    "println(\"Error of third-order approximation at x = $x is: $(sin_error_3(x))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = .01\n",
    "println(\"Error of fifth-order approximation at x = $x is: $(sin_error_5(x))\")\n",
    "println(\"Error of third-order approximation at x = $x is: $(sin_error_3(x))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = .1\n",
    "println(\"Error of fifth-order approximation at x = $x is: $(sin_error_5(x))\")\n",
    "println(\"Error of third-order approximation at x = $x is: $(sin_error_3(x))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Big O Notation: Speed examples\n",
    "\n",
    "Here are a few examples for fundamental computational methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Big O Notation: O(1)\n",
    "\n",
    "**O(1):** algorithm executes in <font color=#3C93DC>**constant time**</font>\n",
    "\n",
    "The size of the input does not affect execution speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Example: accessing a specific location in an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Big O Notation: O(x)\n",
    "\n",
    "**O(x):** algorithm executes in <font color=#3C93DC>**linear time**</font>\n",
    "\n",
    "Execution speed grows linearly in input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Example: inserting an element into an arbitrary location in a 1 dimensional array\n",
    "\n",
    "Bigger array $\\rightarrow$ need to shift around more elements in memory to accomodate the new element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Big O Notation: O(x^2)\n",
    "\n",
    "**O(x):** algorithm executes in <font color=#3C93DC>**quadratic time**</font>\n",
    "\n",
    "More generally called polynomial time for $x^n$\n",
    "\n",
    "Execution speed grows quadratically in input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Example: Two nested loops applying an operation to an array\n",
    "\n",
    "One loop grows linearly, number of operations $=$ number of elements\n",
    "\n",
    "Two loops grows quadratically, need to do one full loop of $x$ operations for each element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What can we compute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Computable general equilibrium models\n",
    "- Linear-quadratic models\n",
    "- RBC models\n",
    "- Rational expectations models\n",
    "- Non-linear dynamic programs\n",
    "- Dynamic games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use computation + theory to answer **quantitative** questions\n",
    "\n",
    "Theory can't give us welfare in dollar terms\n",
    "\n",
    "Theory often relies on strong assumptions like\n",
    "- log utility (lose income vs substitution)\n",
    "- no transactions costs (important friction)\n",
    "- strictly concave objectives (natural phenomena don't follow this)\n",
    "\n",
    "It can be unclear what the cost of these assumptions are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Computer arithmetic\n",
    "\n",
    "## Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Question:** which numbers can be represented by a computer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Before the answer, *how* are numbers physically represented by a computer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**<div class=\"blue\">Binary</div>**: a base 2 number system\n",
    "\n",
    "Each digit can only take on 0 or 1\n",
    "\n",
    "Base 10: each digit can take on 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Question:** which numbers can be represented by a computer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Answer:** a **<font color=#3C93DC>subset</font>** of the rational numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Computers have <font color=#3C93DC>**finite**</font> memory and hard disk space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This imposes a strict limitation on the storage of numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Numbers are stored as: $\\pm mb^{\\pm n}$\n",
    "\n",
    "$m$ is the mantissa/significand  \n",
    "$b$ is the base  \n",
    "$n$ is the exponent\n",
    "\n",
    "All three are integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The significand typically gives the significant digits\n",
    "\n",
    "The exponent scales the number up or down in magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The size of numbers a computer can represent is limited by how much space is typically allocated for a real number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Space allocations are usually 64 bits: 53 for $m$ and 11 for $n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Get the type of the number\n",
    "println(typeof(5.0))\n",
    "println(typeof(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`Int64` means it is a <font color=#3C93DC>**integer**</font> with 64 bits of storage\n",
    "\n",
    "`Float64` means it is a <font color=#3C93DC>**floating point number**</font> with 64 bits of storage\n",
    "\n",
    "Floating point just means $b^{\\pm n}$ can move the decimal point around in the significand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`Int64` and `Float64` are different, this will be important later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Limitations on storage suggest three facts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. There exists a <font color=#3C93DC>**machine epsilon**</font> which denotes the smallest **relative** quantity representible by a computer\n",
    "\n",
    "Machine epsilon is the smallest $\\epsilon$ such that a machine can distinguish $1+\\epsilon > 1 > 1-\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(\"Machine epsilon is $(eps(Float64))\")\n",
    "println(\"Is 1 + ϵ/4 > 1? $(1 + eps(Float64)/4 > 1)\")\n",
    "println(\"Is 1 - ϵ/4 < 1? $(1 - eps(Float64)/4 < 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(\"The smallest representable number larger than 1.0 is $(nextfloat(1.0))\")\n",
    "println(\"The largest representable number smaller than 1.0 is $(prevfloat(1.0))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Machine epsilon changes depending on the amount of storage allocated to floating point numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(\"Machine epsilon is $(eps(Float32))\")\n",
    "println(\"Is 1 + ϵ/4 > 1? $(1 + eps(Float32)/4 > 1)\")\n",
    "println(\"Is 1 - ϵ/4 < 1? $(1 - eps(Float32)/4 < 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This means theres a tradeoff between precision and storage requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Limitations on storage suggest three facts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. There is a <font color=#3C93DC>**smallest representable number**</font>\n",
    "\n",
    "It also depends on storage allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(\"64 bit smallest float is $(floatmin(Float64))\")\n",
    "println(\"32 bit smallest float is $(floatmin(Float32))\")\n",
    "println(\"16 bit smallest float is $(floatmin(Float16))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3. There is a <font color=#3C93DC>**largest representable number**</font>\n",
    "\n",
    "It also depends on storage allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(\"64 bit smallest float is $(floatmax(Float64))\")\n",
    "println(\"32 bit smallest float is $(floatmax(Float32))\")\n",
    "println(\"16 bit smallest float is $(floatmax(Float16))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can overcome these issues (if they ever arise) with arbitrary precision arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(\"The largest 64 bit integer is $(typemax(Int64))\")\n",
    "println(\"Trying to make it bigger is ...troublesome: $(typemax(Int64)+1)\")\n",
    "println(\"It loops us around the number line: $(typemin(Int64))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(\"With SCIENCE we can make it bigger: $(BigInt(typemax(Int64))*1000000)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Key thing to keep in mind\n",
    "\n",
    "**<font color=#3C93DC>The scale of your problem matters</font>**\n",
    "\n",
    "If a parameter or variable is > floatmax or < floatmin, **you will have a very bad time**\n",
    "\n",
    "Scale numbers appropriately (e.g. millions of dollars, not millionths of cents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Computer arithmetic\n",
    "\n",
    "## Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can only represent a finite number of numbers\n",
    "\n",
    "This means we will have error in our computations\n",
    "\n",
    "Error comes in two major forms:\n",
    "\n",
    "1. Rounding\n",
    "2. Truncation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Rounding\n",
    "\n",
    "We will always need to round numbers to the nearest computer representable number, this introduces error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(\"Half of π is: $(π/2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The computer gave us a rational number, but $\\pi/2$ should be irrational"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Truncation\n",
    "\n",
    "Lots of important numbers are defined by infinite sums,\n",
    "\n",
    "$e^x = \\sum_{n=0}^\\infty \\frac{x^n}{n!}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It turns out that computers can't add up infinitely many terms because there is finite space\n",
    "\n",
    "$\\rightarrow$ we need to truncate the sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why does this matter?\n",
    "\n",
    "Errors are small, who cares?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You should!\n",
    "\n",
    "Because errors can propagate and grow as you keep applying an algorithm (e.g. function iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Error example 1\n",
    "\n",
    "Consider a simple quadratic: $x^2-26x+1=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The solution is: $x = 13-\\sqrt{168}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(\"Arbitrary precision: 13 - √168 = $(BigFloat(13-sqrt(168)))\")\n",
    "println(\"64 bit: 13 - √168 = $(13-sqrt(168))\")\n",
    "println(\"32 bit: 13 - √168 = $(convert(Float32,13-sqrt(168)))\")\n",
    "println(\"16 bit: 13 - √168 = $(convert(Float16,13-sqrt(168)))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Error example 2\n",
    "\n",
    "Lets add and subtract some numbers and play around with the associative property of real numbers:\n",
    "\n",
    "- $x = (10^{-20} + 1) - 1$\n",
    "- $y = 10^{-20} + (1 - 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Very clearly we should get $x=y$, but do we? Let's find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = (1e-20 + 1) - 1   # initialize x\n",
    "y = 1e-20 + (1 - 1)   # initialize y\n",
    "x_equals_y = (x == y) # store boolean of whether x == y\n",
    "\n",
    "if x_equals_y\n",
    "    println(\"X equals Y!\")\n",
    "else\n",
    "    println(\"X does not equal Y!\")\n",
    "    println(\"The difference is: $(x-y).\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The two numbers were not equal, we got $y > x$\n",
    "\n",
    "Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Adding numbers of greatly different magnitudes does not always work like you would want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = (1e-20 + 1) - 1   # initialize x\n",
    "y = 1e-20 + (1 - 1)   # initialize y\n",
    "println(\"x is $x\")\n",
    "println(\"y is $y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we added $10^{-20}$ to $1$, it got rounded away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Error example 3\n",
    "\n",
    "Lets just subtract two numbers: 100000.2 - 100000.1\n",
    "\n",
    "We know the answer is: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(\"100000.2 - 100000.1 is: $(100000.2 - 100000.1)\")\n",
    "if (100000.2 - 100000.1) == 0.1\n",
    "    println(\"and it is equal to 0.1\")\n",
    "else\n",
    "    println(\"and it is not equal to 0.1\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Why do we get this error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Neither of the two numbers can be precisely represented by the machine!\n",
    "\n",
    "$100000.1 \\approx 8589935450993459\\times 2^{-33} = 100000.0999999999767169356346130$\n",
    "$100000.2 \\approx 8589936309986918\\times 2^{-33} = 100000.1999999999534338712692261$\n",
    "\n",
    "So their difference won't necessarily be 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Calculus operations\n",
    "## Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Differentiation\n",
    "\n",
    "Derivatives are obviously important in economics for finding optimal allocations, etc\n",
    "\n",
    "The formal definition of a derivative is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\frac{d f(x)}{dx} = \\lim_{h\\rightarrow 0} \\frac{f(x+h)-f(x)}{h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But we can let $t = 1/h$ and reframe this as an infinite limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\frac{d f(x)}{dx} = \\lim_{t\\rightarrow \\infty} \\frac{f(x+1/t)-f(x)}{1/t}$\n",
    "\n",
    "which we know a computer can't handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Computer differentiation\n",
    "\n",
    "How do we perform derivatives on computers if we can't take the limit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**<font color=#3C93DC>Finite difference methods</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Idea: instead of letting $h\\rightarrow 0$, approximate it by letting $h = $ a small number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What does a finite difference approximation look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forward difference\n",
    "The forward difference looks exactly like the formal definition without the limit: $\\frac{d f(x)}{dx} \\approx \\frac{f(x+h)-f(x)}{h}$\n",
    "\n",
    "Works the same for partial derivatives: $\\frac{\\partial g(x,y)}{\\partial x} \\approx \\frac{g(x+h,y)-g(x,y)}{h}$\n",
    "\n",
    "Let's see how it works in practice by calculating derivatives of $x^2$ at $x=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "deriv_x_squared(h,x) = ((x+h)^2 - x^2)/h # derivative function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(\"The deriviative with h=1e-8 is: $(deriv_x_squared(1e-8,2.))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "println(\"The deriviative with h=1e-12 is: $(deriv_x_squared(1e-12,2.))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "println(\"The deriviative with h=1e-30 is: $(deriv_x_squared(1e-30,2.))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "println(\"The deriviative with h=1e-1 is: $(deriv_x_squared(1e-1,2.))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Error, it's there\n",
    "\n",
    "None of the values we chose for $h$ were perfect, but clearly some were better than others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We face two opposing forces:\n",
    "1. We want $h$ to be as small as possible so that we can approximate the limit as well as we possibly can, BUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. If $h$ is small then $f(x+h)$ is close to $f(x)$, we can run into rounding issues like we saw for $h=10^{-30}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can select $h$ in an optimal fashion: $h = \\max\\{|x|,1\\}\\sqrt{\\epsilon}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How much error is in a finite difference?\n",
    "\n",
    "Can we measure the error growth rate in $h$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Perform a first-order taylor expansion of $f(x)$ around $x$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$f(x+h) = f(x) + f'(x)h + O(h^2)$\n",
    "\n",
    "Recall $O(h^2)$ means the error in our approximation grows quadratically in $h$, we only did a linear approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How can we use this to understand the error in our finite difference approximation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Rearrange to obtain: $f'(x) = \\frac{f(x+h) - f(x)}{h} + O(h^2)/h$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forward differences have linearly growing errors\n",
    "\n",
    "$f'(x) = \\frac{f(x+h) - f(x)}{h} + O(h)$ because $O(h^2)/h = O(h)$\n",
    "\n",
    "If we halve $h$, we halve the error in our approximation (ignoring rounding/truncation issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Improvements on the forward difference\n",
    "\n",
    "How can we improve the accuracy of the forward difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, **why** do we have error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Because we are approximating the slope of a tangent curve at $x$ by a secant curve passing through $(x,x+h)$\n",
    "\n",
    "The secant curve has the average slope of $f(x)$ on $[x,x+h]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We want the derivative at $x$, which is on the edge of $[x,x+h]$, how about we **center** $x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Central differences\n",
    "\n",
    "We can approximate $f'(x)$ in a slightly different way: $f'(x) \\approx \\frac{f(x+h)-f(x-h)}{2h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This leaves $x$ in the middle of the interval over which we are averaging the slope of $f(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Is this an improvement on forward differences?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How much error is in a central finite difference?\n",
    "\n",
    "Lets do two second-order Taylor expansions:\n",
    "- $f(x+h) = f(x) + f'(x)h + f''(x)h^2/2! + O(h^3)$\n",
    "- $f(x-h) = f(x) + f'(x)(-h) + f''(x) (-h)^2/2! + O(h^3)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Subtract the two expressions (note that $O(h^3) - O(h^3) = O(h^3)$) and then divide by $2h$ to get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Central differences have quadratic errors\n",
    "$f'(x) = \\frac{f(x+h)-f(x-h)}{2h} + O(h^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Error falls quadratically in $h$, if we halve $h$ we reduce error by 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Optimal selection of $h$ for central differences is $h = \\max\\{|x|,1\\}\\epsilon^{1/3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why use anything but central differences?\n",
    "\n",
    "Suppose we're computing a Jacobian of a multidimensional function, why would we ever use forward differences instead of central differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Accuracy vs time tradeoffs\n",
    "or each central difference we need to compute $g(x_1-h,x_2,...)$ and $g(x_1+h,x_2,...)$ for each $x_i$, but for a forward difference we only need to compute $g(x_1,x_2,...)$ one and then $g(x_1+h,x_2,...)$ for each $x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Forward differences saves on computing time and operations at the expense of accuracy\n",
    "\n",
    "For high dimensional functions it may be worth the tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Higher order finite differences\n",
    "We can use these techniques to approximate higher order derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, take two third order Taylor expansions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $f(x+h) = f(x) + f'(x)h + f''(x)h^2/2! + f'''(x)h^3/3! + O(h^4)$\n",
    "- $f(x+h) = f(x) + f'(x)(-h) + f''(x)(-h)^2/2! + f'''(x)(-h)^3/3! + O(h^4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Add the two expressions and then divide by $h^2$ to get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$f''(x) = \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2} + O(h^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Second derivatives are important for calculating Hessians and checking maxima or minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Differentiation without error?\n",
    "Finite differences put us in between two opposing forces on the size of $h$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can we improve upon finite differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analytic derivatives\n",
    "One way is to code up the actual derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "deriv_x_squared(x) = 2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "println(\"The deriviative is: $(deriv_x_squared(2.))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exact solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Automatic differentiation\n",
    "Coding up analytic derivatives by hand for complex problems is not always great because"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. It can take A LOT of programmer time, more than it is worth\n",
    "2. Humans are suseptible to error in coding or calculating the derivative mathematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://i.imgflip.com/2rk12c.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autodiff: let the computer do it\n",
    "Think about this: any mathematical function you can code up is made up of simple arithmetic operations\n",
    "- add, subtract, divide, multiply\n",
    "- trig functions\n",
    "- exponentials/logs\n",
    "- etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The closed form derivatives of these operations is not hard, it turns out your computer can do it and yield exact solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autodiff: let the computer do it\n",
    "How? There are methods that basically apply a giant chain rule to your whole program,  \n",
    "and break down the derivative into the (easy) component parts that another package knows how to handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# the function, it needs to be written in a particular way because the autodiff package is dumb\n",
    "# *(x,y) is the julia function way to do x*y, autodiff needs to be in terms of julia functions to work correctly ¯\\_(ツ)_/¯\n",
    "ff(x) = *(x[1],x[1]) # x^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2.]                                    # location to evaluate: ff(x) = 2^2\n",
    "g = x -> ForwardDiff.gradient(ff, x)        # g = ∇f\n",
    "println(\"ff'(x) at $(x[1]) is: $(g(x)[1])\") # display graident value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://www.reactiongifs.us/wp-content/uploads/2016/06/oh_yeah_macho_man.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Calculus operations\n",
    "## Integration  (trickier than differentiation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We integrate to do a lot of stuff in economics\n",
    "- Expectations\n",
    "- Add up a continuous measure of things\n",
    "\n",
    "$\\int_D f(x) dx$, $f:\\mathcal{R}^n-\\mathcal{R}$, $ D\\subset\\mathcal{R}^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to think about integrals and their approximations\n",
    "\n",
    "Integrals are effectively infinite sums\n",
    "\n",
    "1 dimensional example:\n",
    "\n",
    "$\\lim_{dx_i\\rightarrow0}\\sum_{i=0}^{(a-b)/dx_i} f(x_i) dx_i$\n",
    "\n",
    "where $dx_i$ is some subset of $[a,b]$ and $x_i$ is some evaluation point (e.g. midpoint of $dx_i$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Infinite limits strike again\n",
    "\n",
    "Just like derivatives, we face an infinite limit as $(a-b)/dx_i \\rightarrow \\infty$\n",
    "\n",
    "We avoid this issue in the same way as derivatives, we replace the infinite sum with something we can handle: a weighted finite sum\n",
    "\n",
    "We will loop back around to the usual Monte Carlo approaches after this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quadrature rules\n",
    "\n",
    "We approximate integrals using a technique called **quadrature**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will focus on two classes of quadrature for now:\n",
    "1. Newton-Cotes (the kind you've seen before)\n",
    "2. Gaussian (probably new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Newton-Cotes quadrature rules\n",
    "\n",
    "Suppose we want to integrate a one dimensional function $f(x)$ over $[a,b]$\n",
    "\n",
    "How would you do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One answer is to replace the function with something easy to integrate: **a piecewise polynomial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Key things to define up front:\n",
    "- $x_i = a + (i-1)/h$ for $i=1,2,...,n$ where $h = \\frac{b-a}{n-1}$\n",
    "\n",
    "$x_i$s are the **quadrature nodes** of the approximation scheme and divide the interval into $n-1$ subintervals of length $h$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Midpoint rule\n",
    "Most basic Newton-Cotes method:\n",
    "1. Split $[a,b]$ into intervals\n",
    "2. Approximate the function in each subinterval by a constant equal to the function at the midpoint of the subinterval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\int_{x_i}^{x_{i+1}} f(x) dx \\approx hf(\\frac{1}{2}(x_{i+1}+x_i))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gives us quadratic convergence in the subinterval size when evenly spaced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Trapezoid rule\n",
    "Increase complexity by 1 degree:\n",
    "2. Approximate the function in each subinterval by a linear interpolation passing through $(x_i,f(x_i))$ and $(x_{i+1},f(x_{i+1}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\int_{x_i}^{x_{i+1}} f(x) dx \\approx \\frac{h}{2}[f(x_i) + f(x_{i+1})]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can aggregate this up to: $\\int_{a}^{b} f(x) dx \\approx \\sum_{i=1}^n w_i f(x_i)$  \n",
    "where $w_1=w_n = h/2$ and $w_i = h$ otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How accurate is this rule?\n",
    "Trapezoid rule is **$O(h^2)$ / first-order exact:** it can integrate any linear function exactly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simpsons rule\n",
    "Increase complexity by 1 degree:\n",
    "2. Let $n$ be odd, then approximate the function across a **pair** of subintervals by a quadratic interpolation passing through $(x_{2i-1},f(x_{2i-i}))$, $(x_{2i},f(x_{2i}))$, and $(x_{2i+1},f(x_{2i+1}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\int_{x_i}^{x_{i+1}} f(x) dx \\approx \\frac{h}{3}[f(x_{2i-1}) + 4f(x_{2i}) + f(x_{2i+1})]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can aggregate this up to: $\\int_{a}^{b} f(x) dx \\approx \\sum_{i=1}^n w_i f(x_i)$  \n",
    "where $w_1=w_n = h/3$, otherwise and $w_i = 4h/3$ if $i$ is even and $w_i = 2h/3$ if $i$ is odd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How accurate is this rule?\n",
    "Trapezoid rule is **$O(h^4)$ / third-order exact:** it can integrate any cubic function exactly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That's weird! Why do we gain 2 orders of accuracy when increasing one order of approximation complexity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. The approximating piecewise quadratic is exact at the end points and midpoint of the conjoined two subintervals\n",
    "2. Clearly the difference between a cubic $f(x)$ and the quadratic in $[x_{2i-1},x_{2i+1}]$ is a cubic function\n",
    "3. You can prove that this cubic function is **odd** with respect to the midpoint $\\rightarrow$ integrating over the first subinterval cancels integrating over the second subinterval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gaussian quadrature rules\n",
    "\n",
    "How did we pick the $x_i$ quadrature nodes for Newton-Cotes rules?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Evenly spaced, no real reason for doing so..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gaussian quadrature selects these nodes more efficiently and relies on **weight functions** $w(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gaussian quadrature rules\n",
    "\n",
    "Gaussian rules try to **exactly integrate** some finite dimensional collection of functions (i.e. polynomials up to some degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For a given order of approximation $n$, the weights $w_1,...,w_n$ and nodes $x_1,...,x_n$ are chosen to satisfy $2n$ **moment matching conditions**:\n",
    "\n",
    "$\\int_I x^kw(x)dx = \\sum_{i=1}^n w_i x^k_i$, for $k=0,...,2n-1$\n",
    "\n",
    "where $I$ is the interval over which we are integrating and $w(x)$ is a given weight function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gaussian quadrature improves accuracy\n",
    "The moment matching conditions pin down $w_i$s and $x_i$s so we can approximate an integral by a weighted sum of the function at the prescribed nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\int_i f(x) w(x)dx \\approx \\sum_{i=1}^n w_i f(x_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gaussian rules are $2n-1$ order exact, we can exactly compute the integral of any polynomial order $2n-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But what do we pick for the weighting function $w(x)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gauss-Legendre\n",
    "We can start out with a simple $w(x) = 1$\n",
    "\n",
    "This can approximate the integral of any function arbitrarily well by increasing $n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gauss-Laguerre\n",
    "Sometimes we want to compute exponentially discounted sums like: $\\int_I f(x) e^{-x} dx$\n",
    "\n",
    "The weighting function $e^{-x}$ is Gauss-Laguerre quadrature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gauss-Hermite\n",
    "Sometimes we want to take expectations of normally distributed variables: $\\int_I f(x) e^{-x^2} dx$\n",
    "\n",
    "There exist packages or look-up tables to get the prescribed weights and nodes for each of these schemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gaussian quadrature takeaways\n",
    "\n",
    "Gaussian quadrature effectively discretizes some distribution $p(x)$ into mass points (nodes) and probabilities (weights) for some other discrete distribution $\\bar{p}(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Given an approximation with $n$ mass points, $X$ and $\\bar{X}$ have identical moments up to order $2n$, and as $n\\rightarrow\\infty$ we have a continuum of mass points and recover the continuous pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Algebra\n",
    "\n",
    "Lots of computational problems break down into linear systems\n",
    "\n",
    "Many non-linear models are linearized\n",
    "\n",
    "How do we **actually** solve these systems inside the machine?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# L-U Factorization\n",
    "\n",
    "If $A$ in $Ax=b$ is upper or lower triangular, we can solve for $x$ recursively via forward/backward substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Consider a lower triangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first element is the only non-zero value in the first row so $x_1$ is easy to solve for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The equation in row 2 contains $x_2$ and the already solved for $x_1$ so we can easily solve for $x_2$ and then continue until we solve for all $x$s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forward substitution\n",
    "Forward substitution gives us solutions\n",
    "\n",
    "$x_i = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1}a_{ij}x_j\\right)$, for all $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Issue: we don't usually luck into an upper or lower triangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "L-U factorization is an algorithm that decomposes $A$ into the product of lower and upper triangular matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# L-U Factorization has two steps\n",
    "1. Factor $A$ into lower $L$ and upper $U$ triangular matrices using Gaussian elimination\n",
    "  1. We can do this for any non-singular square matrix\n",
    "2. Solve for $x$\n",
    "  1. (LU)x = b\n",
    "  2. Solve for $y: Ly = b$ using forward substitution\n",
    "  3. Using the solved $y$, we know $Ux=y$ and can solve with backward substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why bother with this scheme?\n",
    "Why not just numerically invert or use Cramer's rule?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Speed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "L-U requires $\\frac{n^3}{3+n^2}$ operations to solve an $n$x$n$ system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Numerically inverting $A$ requires $n^3+n^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Cramer's rule requires (n+1)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For a 10x10 system this is: 430 vs 1100, vs 40 million operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mechanics of factorizing\n",
    "\n",
    "Gaussian elimination is where we use row operations\n",
    "1. swapping rows\n",
    "2. multiplying by non-zero scalars\n",
    "3. add a scalar multiple of one row to another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "to turn a matrix $(IA)$ into $(LU)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Numerical error blow up\n",
    "Small errors can have big effects, for example:\n",
    "\\begin{align*}\n",
    "\t\\begin{bmatrix}\n",
    "\t    -M^{-1} & 1 \\\\\n",
    "\t\t1 & 1\n",
    "\t\\end{bmatrix} \n",
    "\t\\begin{bmatrix}\n",
    "\t    x_1\\\\\n",
    "\t    x_2\n",
    "\t\\end{bmatrix} \n",
    "\t=\n",
    "\t\\begin{bmatrix}\n",
    "\t    1\\\\\n",
    "\t    2\n",
    "\t\\end{bmatrix} \n",
    "\\end{align*}\n",
    "where $M$ is big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lets use L-U Factorization to solve it: subtract $-M$ times the first row from the second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This yields the L-U factorization\n",
    "\\begin{align*}\n",
    "\t\t\\begin{bmatrix}\n",
    "\t    1&  0 \\\\\n",
    "\t\t0 & 1\n",
    "\t\\end{bmatrix}\n",
    "\t\\begin{bmatrix}\n",
    "\t    -M^{-1} & 1 \\\\\n",
    "\t\t1 & 1\n",
    "\t\\end{bmatrix} \n",
    "\t=\n",
    "\t\\begin{bmatrix}\n",
    "\t    1 & 0\\\\\n",
    "\t    -M & 1\n",
    "\t\\end{bmatrix} \n",
    "\t\\begin{bmatrix}\n",
    "\t    -M^{-1} & 1\\\\\n",
    "\t    0 & M+1\n",
    "\t\\end{bmatrix} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using the substitution methods we obtain that\n",
    "\\begin{align*}\n",
    "\t\\begin{bmatrix}\n",
    "\t    x_1\\\\\n",
    "\t    x_2\n",
    "\t\\end{bmatrix} \n",
    "\t=\n",
    "\t\\begin{bmatrix}\n",
    "\t    M/(M+1)\\\\\n",
    "\t    (M+2)/(M+1)\n",
    "\t\\end{bmatrix} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Numerical issues\n",
    "Both variables are approximately 1 for large $M$, but remember adding small numbers to big numbers causes problems numerically\n",
    "\n",
    "Backwards substitution (when solving $Ux=y$ after we have solved $Ly=b$) first calculates $x_2$ since it is a **recursive** method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If $M=10000000000000000000$, the computer will return $x_2$ is equal to precisely $1$, this is a little wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we then perform the second step of backwards substitution, we solve for $x_1=-M(1-x_2)=0$, this is **very** wrong\n",
    "\n",
    "Large errors like this often occur because diagonal elements are very small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ill-conditioning\n",
    "A matrix $A$ is said to be ill-conditioned if a small perturbation in $b$ yields a large change in $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One way to measure ill-conditioning in a matrix is the elasticity of the solution with respect to $b$,\n",
    "\\begin{gather*}\n",
    "\t\\sup_{||\\delta b || > 0} \\frac{||\\delta x|| / ||x||}{||\\delta b|| / ||b||}\n",
    "\\end{gather*}\n",
    "which yields the percent change in $x$ given a percentage point change in the magnitude of $b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If this elasticity is large, then computer representations of the system of equations can lead to large errors due to rounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Approximate the elasticity by computing the **condition number**\n",
    "\\begin{gather*}\n",
    "\t\\kappa = ||A|| \\cdot ||A^{-1}||\n",
    "\\end{gather*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\kappa$ gives the least upper bound of the elasticity  \n",
    "\n",
    "$\\kappa$ is always larger than one and a rule of thumb is that for every order of magnitude, a significant digit is lost in the computation of $x$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  },
  "livereveal": {
   "theme": "white",
   "transition": "fade"
  },
  "rise": {
   "enable_chalkboard": true,
   "height": "110%",
   "margin-top": 0,
   "scroll": true,
   "top": 0,
   "width": "110%"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
